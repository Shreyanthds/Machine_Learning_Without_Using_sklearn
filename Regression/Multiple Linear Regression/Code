def gradient_descent(X, y, theta, alpha, num_iters):
    # number of samples
    m = len(y)

    # empty array to store the cost at each iteration
    costs = []

    for i in range(num_iters):
        # predicted values
        y_hat = X @ theta
        
        # calculate the derivative of the cost function with respect to each model parameter
        derivative = X.T @ (y_hat - y) / m
    
        # update the model parameters
        theta = theta - alpha * derivative

        # calculate the cost
        cost = cost_function(theta, X, y)

        # store the cost at each iteration
        costs.append(cost)

    return theta, costs
    
    
    import numpy as np

class MultipleLinearRegression:
    
    def _init_(self):
        self.theta = None

    def fit(self, X, y, alpha, num_iters):
        # add a column of ones to X
        X = np.column_stack((np.ones(len(X)), X))
        
        
        # initialize the model parameters
        theta = np.zeros(X.shape[1])

        # run gradient descent
        theta, costs = gradient_descent(X, y, theta, alpha, num_iters)

        # store the model parameters
        self.theta = theta

    def predict(self, X):
        # add a column of ones to X
        X = np.column_stack((np.ones(len(X)), X))

        # make predictions using the model parameters
        y_hat = X @ self.theta

        return y_hat

# create a MultipleLinearRegression object
model = MultipleLinearRegression()

# fit the model to the data
model.fit(Xtrain, Ytrain, alpha=0.1, num_iters=100)

# make predictions using the model
predictions = model.predict(Xtest)
